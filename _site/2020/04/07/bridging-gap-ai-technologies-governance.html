<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="google-site-verification" content="iJ3bc1hdJ7bEpE5lbDoHopnvFezdT5kx0VFo2-H7ycM" />
    <meta name="google-site-verification" content="vq8goVU_JDfJuz6fciLnx-WBUJE1H5oAwpPILuOukns" />

    <title>OxAI - Oxford Artificial Intelligence Society</title>

    <link href="/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="/vendor/fontawesome-free/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="/css/grayscale.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <!-- <link title="timeline-styles" rel="stylesheet" href="https://cdn.knightlab.com/libs/timeline3/latest/css/timeline.css"> -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/events.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/styles.css">
    <link rel="stylesheet" href="/css/jquery.qtip.min.css">
    <!-- <link rel="stylesheet" href="/css/fullcalendar.min.css"> -->
    <link href='/js/packages/core/main.css' rel='stylesheet' />
    <link href='/js/packages/daygrid/main.css' rel='stylesheet' />
    <link href='/js/packages/list/main.css' rel='stylesheet' />
    

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <meta name="description" content="The mission of the Oxford Artificial Intelligence Society is to provide a platform for the interaction of researchers, students, and professionals interested in Artificial Intelligence.">
    <meta http-equiv="content-type" content="text/html;charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">


</head>

<!--Here begins the website itself-->

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <script type="text/javascript">
        var isBlog = false; //For width/height changes to TweenLite
    </script>

    <!-- Navigation (navigation bar on the top)-->

    <!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
  <div class="container">
    <a class="navbar-brand js-scroll-trigger" href="/#page-top">
      <img id="minilogo" src="/img/logo2.png"></img>
        <span class="light">&nbsp;OX</span>AI
    </a>
    <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
      Menu
      <i class="fas fa-bars"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="/events">Events</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/join">Join</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/labs">Labs</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/blog">Blog</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="/#sponsors">Sponsors</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="/#partners">Partners</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="/team">Team</a>
        </li>
      </ul>
    </div>
  </div>
</nav>


    <!-- <style>
    .blog{
        width: 84%;
        margin: 0 auto;
    }
    .blog .title{
        font-size: 24px;
        margin-top: 18px;
        margin-bottom: 8px;
    }
    .blog .content p{
        font-size: 1.2em;
        text-align: left;
    }
    .blog .content .author{
        text-align: right;
    }
    #logo{
        margin-top: 35px;
    }
    @media only screen and (max-width : 768px) {
        .blog{
            width: 90%;
            margin: 0 auto;
        }
        .blog .title{
            font-size: 1.2em;
            margin-bottom: 28px;
        }
        .blog .content p{
            font-size: 1em;
        }
    }
</style> -->

<section class="page blog">
  <div class="container mt-5">
      <div class="row text-center">
        <div class="col-lg-8 mx-auto">
          <h2 class="text-white mb-2">Bridging the Gap between AI Technologies and Governance</h2>
          <h4 class="text-white mb-4">07 Apr 2020</h2>
        </div>
      </div>

      <div class="row w-75 mx-auto">

      <p>AI has become an increasingly visible term in mainstream media as technology continues to proliferate in this modern day. However, the increasing use of AI brings complex implications for public policy that need to be addressed through cooperation between AI researchers and governments. My internship with a financial regulator last summer exposed me to the practical realities that governments face in facilitating and regulating technologies such as FinTech. Given this experience, the AI Ethics and Society course, offered by the Oxford AI Society, piqued my interest because of its focuses on the intersections between governance and technology, and more importantly, the grey spaces between them.</p>

<p>A particular moment in the course that stands out in my memory is when Dr. Ashurst elaborated on how machine bias can inadvertently affect the fairness of real-world processes, such as hiring. Increasingly, companies use video interview software and psychometric testing tools that are powered by AI. These systems use machine learning models to assess candidates in the preliminary stages of the recruitment process. This results in increased efficiency since the system identifies candidates who will progress to the next rounds, and hence reduces the time taken for Human Resource departments to sift through individual applications.</p>

<p>While companies claim that using these software also reduce biases, independent analysts assert that biases could actually be reinforced. An example of such software is HireVue’s emotion recognition, which is used in assessments of prospective candidates during video interviews. The programme functions by analysing word choices, tone and facial movements and providing candidates with a score based on what is deemed desirable. Since the software is based on machine learning, it begins to prefer characteristics that are similar across subsets of successful applicants – hence potentially penalising non-native speakers or those who appear nervous. This bias needs to be manually corrected by developers, but there exists a time lag between recognising and eradicating it. Thus, before such human intervention occurs, numerous candidates would have been subject to the bias in the algorithm.</p>

<p>Having gone through such application processes for internships myself, I find it rather perplexing that it is AI in its early stages that can either make or break my chances of success, and that individuals first have to get through the AI system in order to get a face-to-face interview with a real person only in the final rounds.</p>

<p>Therefore, I believe that governments and regulatory organisations need to do more to address the societal issues posed by AI. The course highlighted that AI use is currently concentrated among corporations and firms, so I think there needs to be greater cooperation between the public and private sectors in addressing the ethical risks posed by AI. To be frank, however, I am sceptical about the viability of regulating rapidly adapting technologies, simply because policymakers have been plagued by the inertia of being unable to promptly react to technological change. This is underscored by a more fundamental (and unfortunate) ignorance or perhaps even complacency about machine intelligence. A prominent example of this is Mark Zuckerberg’s interrogation by members of the US Congress in 2018, who seemed completely unaware of Facebook’s operations.</p>

<p>As an aspiring policymaker, I think governments can certainly devote more resources and research efforts to understanding and tackling the ethical and societal challenges posed by AI. To that extent, this course is illuminating in how the lectures present novel solutions to AI governance and the relevance of research done at Oxford to answering the questions posed by the emergence and expansion of AI technologies.</p>

<p><em>Introduction to AI Ethics (and Society) was a five-part course organized by OxAI and taught by Dr. Ashurst of the Future of Humanity Institute in February and March of 2020. The course examined the most relevant and important issues that dominate the debate around ethics in AI through a series of lectures and discussion. Natasha Vincent is a student at the University of Oxford and a participant in the course.</em></p>


      <p class="author">Written by
      <br><i>Natasha Vincent</i>
      <br><i></i></p>

      </div>
</div>
</section>

    <!--Welcome section-->
    <!-- <div id="large-header" class="large-header container">
      <canvas id="demo-canvas"></canvas>
      <div class="row welcome">
        <div class="welcome2">
          <img id="logo" src="/img/logo.png"/>
            <div class="blog">
                <h3 class="title">
                    Bridging the Gap between AI Technologies and Governance - 07 Apr 2020
                </h3>
                <div class="content">

                    <p>AI has become an increasingly visible term in mainstream media as technology continues to proliferate in this modern day. However, the increasing use of AI brings complex implications for public policy that need to be addressed through cooperation between AI researchers and governments. My internship with a financial regulator last summer exposed me to the practical realities that governments face in facilitating and regulating technologies such as FinTech. Given this experience, the AI Ethics and Society course, offered by the Oxford AI Society, piqued my interest because of its focuses on the intersections between governance and technology, and more importantly, the grey spaces between them.</p>

<p>A particular moment in the course that stands out in my memory is when Dr. Ashurst elaborated on how machine bias can inadvertently affect the fairness of real-world processes, such as hiring. Increasingly, companies use video interview software and psychometric testing tools that are powered by AI. These systems use machine learning models to assess candidates in the preliminary stages of the recruitment process. This results in increased efficiency since the system identifies candidates who will progress to the next rounds, and hence reduces the time taken for Human Resource departments to sift through individual applications.</p>

<p>While companies claim that using these software also reduce biases, independent analysts assert that biases could actually be reinforced. An example of such software is HireVue’s emotion recognition, which is used in assessments of prospective candidates during video interviews. The programme functions by analysing word choices, tone and facial movements and providing candidates with a score based on what is deemed desirable. Since the software is based on machine learning, it begins to prefer characteristics that are similar across subsets of successful applicants – hence potentially penalising non-native speakers or those who appear nervous. This bias needs to be manually corrected by developers, but there exists a time lag between recognising and eradicating it. Thus, before such human intervention occurs, numerous candidates would have been subject to the bias in the algorithm.</p>

<p>Having gone through such application processes for internships myself, I find it rather perplexing that it is AI in its early stages that can either make or break my chances of success, and that individuals first have to get through the AI system in order to get a face-to-face interview with a real person only in the final rounds.</p>

<p>Therefore, I believe that governments and regulatory organisations need to do more to address the societal issues posed by AI. The course highlighted that AI use is currently concentrated among corporations and firms, so I think there needs to be greater cooperation between the public and private sectors in addressing the ethical risks posed by AI. To be frank, however, I am sceptical about the viability of regulating rapidly adapting technologies, simply because policymakers have been plagued by the inertia of being unable to promptly react to technological change. This is underscored by a more fundamental (and unfortunate) ignorance or perhaps even complacency about machine intelligence. A prominent example of this is Mark Zuckerberg’s interrogation by members of the US Congress in 2018, who seemed completely unaware of Facebook’s operations.</p>

<p>As an aspiring policymaker, I think governments can certainly devote more resources and research efforts to understanding and tackling the ethical and societal challenges posed by AI. To that extent, this course is illuminating in how the lectures present novel solutions to AI governance and the relevance of research done at Oxford to answering the questions posed by the emergence and expansion of AI technologies.</p>

<p><em>Introduction to AI Ethics (and Society) was a five-part course organized by OxAI and taught by Dr. Ashurst of the Future of Humanity Institute in February and March of 2020. The course examined the most relevant and important issues that dominate the debate around ethics in AI through a series of lectures and discussion. Natasha Vincent is a student at the University of Oxford and a participant in the course.</em></p>


                    <p class="author">Written by
                    <br><i>Natasha Vincent</i>
                    <br><i></i></p>
                </div>
            </div>
        </div>
    </div>
</div> -->


<!-- <script type="text/javascript">
    var isBlog = true; //For width/height changes to TweenLite
</script> -->


    <script src="/js/lazysizes.min.js" async=""></script>
    <!-- Custom Theme JavaScript -->
    <script src="/vendor/jquery/jquery.min.js"></script>
    <!-- <script src="/js/grayscale.js"></script> -->
    <script type="text/javascript" src="/js/TweenLite.min.js"></script>

    <!-- Footer -->
    <footer class="bg-black small text-center text-white-50">
      <div class="container">
        Copyright &copy; OxAI 2019
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="/vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="/js/grayscale.min.js"></script>

    <!-- Full calendar -->
    <script src='js/moment.min.js'></script>
    <script src='/js/jquery.qtip.min.js'></script>
    <!-- <script src='/js/fullcalendar/fullcalendar.min.js'></script>
    <script src='/js/fullcalendar/gcal.js'></script> -->

    <script src='/js/packages/core/main.js'></script>
    <script src='/js/packages/interaction/main.js'></script>
    <script src='/js/packages/daygrid/main.js'></script>
    <script src='/js/packages/list/main.js'></script>
    <script src='/js/packages/google-calendar/main.js'></script>

    <script src="/js/script.js"></script>

</body>

</html>
